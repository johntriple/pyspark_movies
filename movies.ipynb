{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4368\\916702730.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#spark.stop()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#spark=SparkSession.builder.config(conf=con).appName(\"databases2\").getOrCreate()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mspark\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"databases2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#This line is commented when cluster mode is running\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                         \u001b[1;31m# This SparkContext may be an existing one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                     \u001b[1;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                     \u001b[1;31m# by all sessions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32mD:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "#the following 4 lines are used when running the program in cluster mode instead of locally\n",
    "#con = pyspark.SparkConf().setAll([('spark.executor.memory','512m'), ('spark.executor.cores', '1'), ('spark.driver.cores','1'), ('spark.driver.memory','1g')])\n",
    "#con.setMaster('spark://192.168.1.3:7077')\n",
    "#spark.stop()\n",
    "#spark=SparkSession.builder.config(conf=con).appName(\"databases2\").getOrCreate()\n",
    "spark=SparkSession.builder.appName(\"databases2\").getOrCreate() #This line is commented when cluster mode is running\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating           timestamp\n",
       "0       1        2     3.5 2005-04-02 23:53:47\n",
       "1       1       29     3.5 2005-04-02 23:31:16\n",
       "2       1       32     3.5 2005-04-02 23:33:39\n",
       "3       1       47     3.5 2005-04-02 23:32:07\n",
       "4       1       50     3.5 2005-04-02 23:29:40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings=spark.read.csv('rating.csv',inferSchema=True,header=True)\n",
    "ratings=ratings.withColumn('timestamp',F.to_timestamp(ratings.timestamp,'yyyy-MM-dd HH:mm:ss'))#typecasts timestamp column to a timestamp datatype\n",
    "ratings.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         Allgenres|\n",
      "+------------------+\n",
      "|(no genres listed)|\n",
      "|            Action|\n",
      "|         Adventure|\n",
      "|         Animation|\n",
      "|          Children|\n",
      "|            Comedy|\n",
      "|             Crime|\n",
      "|       Documentary|\n",
      "|             Drama|\n",
      "|           Fantasy|\n",
      "|         Film-Noir|\n",
      "|            Horror|\n",
      "|              IMAX|\n",
      "|           Musical|\n",
      "|           Mystery|\n",
      "|           Romance|\n",
      "|            Sci-Fi|\n",
      "|          Thriller|\n",
      "|               War|\n",
      "|           Western|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies=spark.read.csv('movie.csv',inferSchema=True,header=True)\n",
    "movies=movies.withColumn('year',F.regexp_extract(('title'),\"(?s).*\\(([^()]+)\\)\",1))#extracts the year from the title column\n",
    "movies=movies.withColumn('year',movies['year'].cast(IntegerType())) #typecasts newly made year column to an integer type\n",
    "movies=movies.withColumn('title',F.regexp_replace('title','\\([^)]*\\)',''))#removes parentheses\n",
    "movies=movies.withColumn('title',F.regexp_replace('title','^\\s+',''))#removes whitespace begining of line\n",
    "movies=movies.withColumn('title',F.regexp_replace('title','\\s+$',''))#removes whitespace end of line\n",
    "movies=movies.withColumn('title',F.initcap('title'))#makes the entire of title column to have 1st letter of every word capital case while the rest become lower case\n",
    "movies=movies.filter(movies.year.isNotNull())#drop 22 movies for the dataset as they dont follow the norm of having (year) after the title in the title collumn\n",
    "#the next eleven lines are used to find out the different categories in genres column they are displayed alphabetically in col2[0]\n",
    "moviesplit=movies.withColumn('genres',F.explode(F.split(('genres'),'\\|')))   \n",
    "movies2=movies.select('movieId','title','year',F.split('genres','\\|').alias('col2')) \n",
    "movies2_sizes=movies2.select(F.size('col2').alias('col2'))\n",
    "movies2_max=movies2_sizes.agg(F.max('col2'))\n",
    "nb_columns=movies2_max.collect()[0][0]\n",
    "moviesres=movies2.select('title','movieId','year',*[movies2['col2'][i] for i in range(nb_columns)])\n",
    "moviesres=moviesres.sort('col2[0]').dropDuplicates(subset=['col2[0]'])\n",
    "genres=moviesres.drop('year','title','movieId','col2[1]','col2[2]','col2[3]','col2[4]','col2[5]','col2[6]','col2[7]','col2[8]','col2[9]')\n",
    "genres = genres.withColumnRenamed(\"col2[0]\", \"Allgenres\")\n",
    "genres.sort('Allgenres').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+----+\n",
      "|movieId|               title|              genres|year|\n",
      "+-------+--------------------+--------------------+----+\n",
      "|      1|           Toy Story|Adventure|Animati...|1995|\n",
      "|      2|             Jumanji|Adventure|Childre...|1995|\n",
      "|      3|    Grumpier Old Men|      Comedy|Romance|1995|\n",
      "|      4|   Waiting To Exhale|Comedy|Drama|Romance|1995|\n",
      "|      5|Father Of The Bri...|              Comedy|1995|\n",
      "|      6|                Heat|Action|Crime|Thri...|1995|\n",
      "|      7|             Sabrina|      Comedy|Romance|1995|\n",
      "|      8|        Tom And Huck|  Adventure|Children|1995|\n",
      "|      9|        Sudden Death|              Action|1995|\n",
      "|     10|           Goldeneye|Action|Adventure|...|1995|\n",
      "+-------+--------------------+--------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4141</td>\n",
       "      <td>Mark Waters</td>\n",
       "      <td>2009-04-24 18:19:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>208</td>\n",
       "      <td>Dark Hero</td>\n",
       "      <td>2013-05-10 01:41:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>353</td>\n",
       "      <td>Dark Hero</td>\n",
       "      <td>2013-05-10 01:41:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>521</td>\n",
       "      <td>Noir Thriller</td>\n",
       "      <td>2013-05-10 01:39:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>592</td>\n",
       "      <td>Dark Hero</td>\n",
       "      <td>2013-05-10 01:41:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId            tag           timestamp\n",
       "0      18     4141    Mark Waters 2009-04-24 18:19:40\n",
       "1      65      208      Dark Hero 2013-05-10 01:41:18\n",
       "2      65      353      Dark Hero 2013-05-10 01:41:19\n",
       "3      65      521  Noir Thriller 2013-05-10 01:39:43\n",
       "4      65      592      Dark Hero 2013-05-10 01:41:18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags=spark.read.csv('tag.csv',inferSchema=True,header=True)\n",
    "tags=tags.withColumn('timestamp',F.to_timestamp(tags.timestamp,'yyyy-MM-dd HH:mm:ss'))#typecasts timestamp column to a timestamp datatype\n",
    "tags=tags.withColumn('tag',F.regexp_replace('tag','\\([^)]*\\)',''))#removes parentheses\n",
    "tags=tags.withColumn('tag',F.regexp_replace('tag','^\\s+',''))#removes whitespace begining of line\n",
    "tags=tags.withColumn('tag',F.regexp_replace('tag','\\s+$',''))#removes whitespace end of line\n",
    "tags=tags.withColumn('tag',F.initcap('tag'))#makes the entire of tag column to have 1st letter of every word capital case while the rest become lower case\n",
    "tags=tags.filter(tags.timestamp.isNotNull()) #drop rows where timestamp collumn does not contain a timestamp\n",
    "tags.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagId</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18th Century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1920s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1930s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tagId           tag\n",
       "0      1           007\n",
       "1      2           007\n",
       "2      3  18th Century\n",
       "3      4         1920s\n",
       "4      5         1930s"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genometags=spark.read.csv('genome_tags.csv',inferSchema=True,header=True)\n",
    "genometags=genometags.withColumn('tag',F.regexp_replace('tag','\\([^)]*\\)',''))#removes parentheses\n",
    "genometags=genometags.withColumn('tag',F.regexp_replace('tag','^\\s+',''))#removes whitespace begining of line\n",
    "genometags=genometags.withColumn('tag',F.regexp_replace('tag','\\s+$',''))#removes whitespace end of line\n",
    "genometags=genometags.withColumn('tag',F.initcap('tag'))#makes the column tag to have 1st letter of every word capital case while the rest become lower case\n",
    "genometags.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tagId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genometags.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|  title|count|\n",
      "+-------+-----+\n",
      "|Jumanji|22243|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1=movies.join(ratings,['movieId'],'inner').select('title','UserId').where(movies.title=='Jumanji').groupBy('title').count()\n",
    "q1.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               title|   tag|\n",
      "+--------------------+------+\n",
      "|       101 Reykjavik|Boring|\n",
      "|    12 Years A Slave|Boring|\n",
      "|                1408|Boring|\n",
      "|1492: Conquest Of...|Boring|\n",
      "|2001: A Space Ody...|Boring|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2=movies.join(tags,['movieId'],'inner').select('title','tag').where(tags.tag=='Boring').dropDuplicates(subset=['title']).orderBy('title')\n",
    "q2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|rating|userId|\n",
      "+------+------+\n",
      "|   4.0| 10573|\n",
      "|   5.0| 19837|\n",
      "|   4.5| 23333|\n",
      "|   5.0| 25004|\n",
      "|   4.5| 31338|\n",
      "+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q3=ratings.join(tags,['userId','movieID'],'inner').select('rating','userId').where(tags.tag=='Bollywood')\n",
    "q3=q3.filter(q3.rating>3).dropDuplicates(subset=['userId']).sort('userId')\n",
    "q3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|avg(rating)|\n",
      "+--------------------+-----------+\n",
      "|                1971|        5.0|\n",
      "|           Abendland|        5.0|\n",
      "|Codes Of Gender, The|        5.0|\n",
      "|            Giorgino|        5.0|\n",
      "|Into The Middle O...|        5.0|\n",
      "|     Latin Music Usa|        5.0|\n",
      "|        Rocaterrania|        5.0|\n",
      "| The Floating Castle|        5.0|\n",
      "|Victor And The Se...|        5.0|\n",
      "|Year Zero: The Si...|        5.0|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#πριν την διορθωση της εκφωνησης ειχα υποθεση πως αναφεροσασταν για τις ταινιες που βγηκαν το 2005 και οχι για τα ratings καθως δουλευει το query απλα το γραφω σε comment αντι να το σβησω\n",
    "#q4=movies.join(ratings,['movieId'],'inner').select('title','rating','year').where(movies.year==2005).groupBy('title').avg('rating').sort(['avg(rating)'],ascending=False).limit(10).sort('title')\n",
    "#q4.show()\n",
    "q4=movies.join(ratings,['movieId'],'inner').select('title','rating','timestamp').groupBy('title').avg('rating').sort(['avg(rating)'],ascending=False).limit(10).sort('title')\n",
    "q4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+----+\n",
      "|              title|             tag|year|\n",
      "+-------------------+----------------+----+\n",
      "|   A Grain Of Truth|   Borys Lankosz|2015|\n",
      "|A Walk In The Woods|      Ken Kwapis|2015|\n",
      "|       Advantageous|  Jennifer Phang|2015|\n",
      "|As We Were Dreaming| Based On A Book|2015|\n",
      "|    Average Italian|Marcello Macchia|2015|\n",
      "+-------------------+----------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q5=movies.join(tags,['movieId'],'inner').select('title','tag','year').where(movies.year==2015).sort('title').dropDuplicates(subset=['title'])\n",
    "q5.show(5)\n",
    "#σε περιπτωση που στην εκφωνηση ζηταγατε για τα timestamps που εγιναν το 2015 και οχι τις ταινιες που βγηκαν το 2015 το κατω query ειναι το σωστο\n",
    "#q5=movies.join(tags,['movieId'],'inner').select('title','tag','year','timestamp').where(F.year('timestamp')==2015).sort('title').dropDuplicates(subset=['title'])\n",
    "#q5.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               title|count|\n",
      "+--------------------+-----+\n",
      "|        Pulp Fiction|67310|\n",
      "|        Forrest Gump|66172|\n",
      "|Shawshank Redempt...|63366|\n",
      "|Silence Of The La...|63299|\n",
      "|       Jurassic Park|59715|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q6=movies.join(ratings,['movieId'],'inner').select('title','rating').groupBy('title').count().sort('count',ascending=False)\n",
    "q6.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|131160|    3|\n",
      "| 28507|    1|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q795=ratings.select('userId','rating').where(F.year('timestamp')==1995).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q796=ratings.select('userId','rating').where(F.year('timestamp')==1996).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q797=ratings.select('userId','rating').where(F.year('timestamp')==1997).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q798=ratings.select('userId','rating').where(F.year('timestamp')==1998).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q799=ratings.select('userId','rating').where(F.year('timestamp')==1999).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q700=ratings.select('userId','rating').where(F.year('timestamp')==2000).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q701=ratings.select('userId','rating').where(F.year('timestamp')==2001).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q702=ratings.select('userId','rating').where(F.year('timestamp')==2002).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q703=ratings.select('userId','rating').where(F.year('timestamp')==2003).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q704=ratings.select('userId','rating').where(F.year('timestamp')==2004).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q705=ratings.select('userId','rating').where(F.year('timestamp')==2005).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q706=ratings.select('userId','rating').where(F.year('timestamp')==2006).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q707=ratings.select('userId','rating').where(F.year('timestamp')==2007).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q708=ratings.select('userId','rating').where(F.year('timestamp')==2008).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q709=ratings.select('userId','rating').where(F.year('timestamp')==2009).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q710=ratings.select('userId','rating').where(F.year('timestamp')==2010).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q711=ratings.select('userId','rating').where(F.year('timestamp')==2011).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q712=ratings.select('userId','rating').where(F.year('timestamp')==2012).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q713=ratings.select('userId','rating').where(F.year('timestamp')==2013).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q714=ratings.select('userId','rating').where(F.year('timestamp')==2014).groupBy('userId').count().sort('count',ascending=False).show(10)\n",
    "#q715=ratings.select('userId','rating').where(F.year('timestamp')==2015).groupBy('userId').count().sort('count',ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----+\n",
      "|   genres|        title|count|\n",
      "+---------+-------------+-----+\n",
      "|   Action|Jurassic Park|59715|\n",
      "|Adventure|Jurassic Park|59715|\n",
      "|Animation|    Toy Story|49695|\n",
      "| Children|    Toy Story|49695|\n",
      "|   Comedy| Pulp Fiction|67310|\n",
      "+---------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q8=movies.join(ratings,['movieId'],'inner').select('title','rating','genres').withColumn('genres',F.explode(F.split(('genres'),'\\|')))\n",
    "q8=q8.filter(q8.genres!='(no genres listed)')\n",
    "q8=q8.groupBy('genres','title').count().orderBy(F.asc('genres'),F.desc('count')).dropDuplicates(subset=['genres']).sort('genres')\n",
    "q8.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  Users|\n",
      "+-------+\n",
      "|4281178|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q9=ratings.select(F.year('timestamp').alias('year'),F.month('timestamp').alias('month'),F.dayofmonth('timestamp').alias('day'),F.hour('timestamp').alias('hour'),'movieID').groupBy('year','month','day','hour','movieID').count()\n",
    "q9=q9.filter('count>1')\n",
    "q9=q9.agg(F.sum('count').alias('Users'))\n",
    "q9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|   genres|count|\n",
      "+---------+-----+\n",
      "|   Action|  363|\n",
      "|Adventure|  401|\n",
      "|Animation|  253|\n",
      "| Children|  255|\n",
      "|   Comedy| 1329|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp=movies.join(tags,['movieId'],'inner').select('userId','title','genres','movieID').where(tags.tag=='Funny')\n",
    "q10=temp.join(ratings,['userId','movieID'],'inner').select('title','genres').where(ratings.rating>3.5).withColumn('genres',F.explode(F.split(('genres'),'\\|')))\n",
    "q10.groupBy('genres').count().sort('genres').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
